# README


## Описание задачи

### Трек SberOnline

Задачу можно разделить на три части:

1. Разработать систему классификации отзывов пользователей в AppStore / Google Play:
по тексту отзыва определять ответственную команду
  * В виду отсутствия разметки для классификации - добавить возможность интерактивного взаимодействия с системой и ручной разметки
  * Производить сопоставление отзывов по похожей проблеме
2. Классификация тональности отзывов (баг, дефект, замечание, пожелание)


## Технические особенности

### Проблема №0 - Очистка датасета

Прежде чем проводить любой анализ данных, нам необходимо очистить данные. Выбирая между датасетами **Play Store** и **AppStore**, мы выбрали последний, т.к в нем больше актуальных для нас данных. Первая проблема была связана с кодировкой в данных. После ее решения, при первом рассмотрении данных легко заметить отноительно большое количество пустых столбцов. Удаляем пустые столбцы и избавляемся от NaN во всем датасете. Данные готовы!
 
### Проблема №1 - Отсутствие разметки для классификации по командам

#### Ключевые слова

Для того, чтобы иметь возможность сопоставлять команды и отзывы, мы решили представить их в одном **векторном пространстве**. Для этого для каждой команды был составлен список **ключевых слов**, описывающих зону ответственности этой команды. Массив ключевых слов, содержащихся во всем датасете отзывов были отсортированы по частоте встречаемости и из первой **1000** для команд были выбраны соответствующие слова.

При этом ключевые слова выбирались из отзыва и его названия, поскольку в последнем часто содержится основная информация об отзыве.

`"iOS Platform": ["touch id", "face id", "виджет избранное", "геокарты", "адресная книга", "механизм отправки событий аналитики", "аутентификация", "регистрация", "авторизация", "карта", "темная тема", "вход", "виджет", "обновление", "версия", "ios", "ipad", "вылет", "лагает", "тормозит", "айфон", "запуск", "загрузка", "отпечаток", "авторизаци", "зависание", "обнова", "глюк", "звук", "фейс", "долгая загрузка", "быстрый вход", "отображение", "iphone xr", "фэйс", "iphone 6", "пароль", "ввод пароля", "iphone x", "черная тема", "ошибка приложения", "iphone xs", "ipad pr"]`

Ключевые слова определялись при помощи двух методов: 
1. [TextRank](https://github.com/RaRe-Technologies/gensim) - Page Ranking подход для задачи суммаризации
2. [TermExtractor](https://github.com/igor-shevchenko/rutermextract) - подход, основанный на POS(part-of-speech) tagging

**Выводы**: После просмотра ключевых слов полученных в каждом подходе оказалось, что использование **TextRank** слишком опирается на претрейновые эмбеддинги и плохо подходит для наших текстов из специфической области, в то время как **TermExtract** опирается на данные из нашего корпуса текстов и выделяет осмысленные ключевые слова.

| Название+Отзыв      | TermExtract keywords            | Text Rank  keywords |
| ------------- |:------------------:| -----:|
| 'Приложение не открывается после обновления!!!! Уже неделю пытаюсь открыть ни у меня ни у моих друзей не получается'     | 'обновление', 'неделя', 'мои друзья', 'приложение' | 'пытаюсь' |
| Не могу скачать так как требует подключения Wi-fi     | 'подключение wi-fi' |   'требует' |

Код со сравнением находится в файле [3_baseline_oneHot.ipynb](https://github.com/korney3/SberCodeKeyIdea/blob/master/Code/3_baseline_oneHot.ipynb)

#### Предсказательные модели

1. **Baseline Keywords Matching**

В качестве бейзлайна использовалось предсказание ответственной за отзыв команды по взвешенному количеству пересечений ключевых слов в отзыве и в описании команды.

Полученные предсказание расположены в файле [team_labeled.pkl](https://github.com/korney3/SberCodeKeyIdea/blob/master/Resources/3_predictions/team_labeled.pkl)

2. **One-Hot vectorization**

Следующей итерацией был перевод отзывов и ключевых слов групп в вектора при помощи **One-Hot vectorization** метода. Предсказание команды производилось по двум метрикам - **euclidean distance** (по наименьшему расстоянию) и **cosine distance** (по наибольшему значению). 

**Выводы**: **euclidean distance** предсказывал команду с наименьшим числом ключевых слов для всех отзывов, поэтому в данном методе эта метрика не использовалась и выбор пал на **cosine distance**.

Файл с кодом для запуска модели расположен в [3_baseline_oneHot.ipynb](https://github.com/korney3/SberCodeKeyIdea/blob/master/Code/3_baseline_oneHot.ipynb), предсказания лежат в файле [onehot_cos_preds.csv](https://github.com/korney3/SberCodeKeyIdea/blob/master/Resources/3_predictions/tfidf_cos_preds.csv)

3. **Flair embeddings** and **BERT embeddings**

В качестве следующей модели были использованы претренированные эмбеддинги библиотеки [Flair](https://github.com/flairNLP/flair) на базе **FastText** для русского языка и [BERT](ttps://github.com/UKPLab/sentence-transformers). Среди всевозможных вариантов эмбеддингов Word2Vec были выбраны эти две, поскольку они были претренированы для экстракции эмбедингов из предложений.

Предсказания производились для двух метрик - **euclidean distance** (по наименьшему расстоянию) и **cosine distance** (по наибольшему значению).

Файл с кодом для запуска модели расположен в [5_embeddings.ipynb](https://github.com/korney3/SberCodeKeyIdea/blob/master/Code/5_embeddings.ipynb), предсказания лежат в файлах [teams_predictions_flair.csv](https://github.com/korney3/SberCodeKeyIdea/blob/master/Resources/3_predictions/teams_predictions_flair.csv)
 и [teams_predictions_bert.csv](https://github.com/korney3/SberCodeKeyIdea/blob/master/Resources/3_predictions/teams_predictions_bert.csv)
 
#### Выводы

Для полученных моделей были посчитаны метрики качества - **accuracy**, **recall**, **f1_score**.

Поскольку разметки для всех данных нет, из общего корпуса отзывов были случайно выбраны и размечены 400 отзывов. При этом в соответствие каждому отзыву ставилось сразу несколько классов, поскольку отзывы потенциально содердат в себе проблемы, относящиеся к разным командам.

Размеченные данные лежат в файле [marked.csv](https://github.com/korney3/SberCodeKeyIdea/blob/master/Resources/marked.csv)

![alt-текст](https://github.com/korney3/SberCodeKeyIdea/blob/master/Presentation%20materials/metrics.png)

1. Использованные нами подходы в основном превосходят результаты бейзлайна (**Keywords matching**)

2. Несмотря на то, что по средним значениям метрик наилучшие предсказания дает **One-Hot vectorization**, стандартное отклонение показывает, что для более грамотного сравнения этой модели и **Flair embeddings** and **BERT embeddings** нужно большее количество размеченных данных.

3. **Flair embeddings** and **BERT embeddings** позволяют **без переобучения модели** добавлять новые команды с их ключами и делать предсказания сразу же.

### Проблема №2 - Отсутствие разметки для классификации по тональности
Довольно проблематично найти датасет русскоязычных отзывов с размеченной тональностью. Поэтому для обучения модели тональности, мы использовали русскоязычный датасет с твитами. После обучения и тестирования модели, нам удалось достигнуть качества в 75% по метрике accuracy.

### Проблема №3 Объединение отзывов по темам

1. **Tематическое моделирование** - это статистический метод обработки текстовой информации на естественном языке, позволяющий в процессе моделирования устанавливаются распределения документов над темами и тем над отдельными словами.

Одним из классических представителей алгоритмов тематического моделирования является LDA (Latent Dirichlet Allocation). В случае LDA каждый документ в корпусе характеризуется распределением Дирихле над скрытыми (латентными) переменными (темами), и каждая тема характеризуется другим распределением Дирихле по всем отдельным словам словаря.

Таким образом каждый документ представляет собой смесь различных тем, каждая тема формируется своим набором терминов.

В отличие от традиционного Bag-of-word подхода для извлечения текстовых объектов мы не получаем большую разреженную матрицу терм-документ, содержащую много «шумной» информации, а выстраиваем мосты между отдельными словами и документами через скрытые тематики и мягкую кластеризацию, выполняя попутно операцию снижения признакового пространства.
 
Подобрать оптимальное число тематик позволяют текие метрики как
Сложность (Perplexity) модели и согласованность (Coherence) тем построенной модели.

Файл с кодом можно посмотреть [8_topic_modeling.ipynb](https://github.com/korney3/SberCodeKeyIdea/blob/master/Code/8_topic_modeling.ipynb)

Результаты визуализации [lda_2.html](https://github.com/korney3/SberCodeKeyIdea/blob/master/Presentation%20materials/lda_2.html)

**Выводы**: По итогу тематического моделирования было построено выделение тем из датасета с отзывами

2. **KMeans кластеризация**

На базе векторов **Flair embeddings** and **BERT embeddings** была сделана попытка определить оптимальное количество кластеров, на которые можно было бы разбить все отзывы при помощи **Elbow method**

|Embeddings| Elbow method      | PSA reduced clusterization  | 
| ------------- |:------------------:| -----:|
| Flair     | ![alt-текст](https://github.com/korney3/SberCodeKeyIdea/blob/master/Presentation%20materials/elbow_flair.png)    | ![alt-текст](https://github.com/korney3/SberCodeKeyIdea/blob/master/Presentation%20materials/cluster_flair.png) |
| Bert   | ![alt-текст](https://github.com/korney3/SberCodeKeyIdea/blob/master/Presentation%20materials/elbow_bert.png) |   ![alt-текст](https://github.com/korney3/SberCodeKeyIdea/blob/master/Presentation%20materials/cluster_bert.png)|

**Выводы**: Наилучшее количество кластеров очень мало для выделения тем - ~5 кластеров для обоих типов эмбеддингов

3. **KMeans кластеризация по релизам**

В качестве идеи мы рассмотрели возможную кластеризацию среди отзывов в рамках одного релиза.



## Контакты

Egor Yusupov - Front-end, Design - @EgorYusupov

Max Egorov  - Data Scientist - @egorov_m

Alisa Alenicheva  - Data Scientist - @korney3


